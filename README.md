# Trabalho-de-Big-Data-em-Python
Etapa 2 do projeto - Pipeline de dados, limpeza e cálculos de média. 

Importamos as Bibliotecas Pandas e PySparks para iniciar nosso Programa.
Pandas é uma biblioteca usada para análise e manipulação de dados.
PySparks é a interface do Python para o Apache Spark. É ideal para projetos em Big Data, quando o volume é grande e precisa ser processado com mais velocidade. 

Depois de importarmos as bibliotecas, criamos uma sessão Spark que tem a função de dar um nome à aplicação e 
criar uma sessão se não existir.

Colocamos o caminho do CSV, onde está nosso projeto.

Lemos o caminho CSV com cabeçalho.

Mostraramos o schema e primeiras linhas do nossos dados.

Filtramos apenas 2025.

Escolhemos uma média por ano.

E finalizamos encerrando sessão.




